{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 💬 **Prompts** – *Teach LLMs What You Want Them to Do*\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 What It Does\n",
    "\n",
    "`Prompts` in MCP let you define **few-shot examples, templates, and instructions** that guide how your LLM tools behave. You can write simple prompts, or create reusable, dynamic prompt components that integrate with your structured tools.\n",
    "\n",
    "Think of it as: **Instructions + Examples + Input Template = Smart LLM Output**\n",
    "\n",
    "---\n",
    "\n",
    "## 🚀 Common Use-Cases\n",
    "\n",
    "| Scenario              | Why Use Prompts                                |\n",
    "| --------------------- | ---------------------------------------------- |\n",
    "| 🧠 Few-shot learning  | Provide examples to guide the LLM              |\n",
    "| 🗂️ Consistent output | Use templates for repeatable formats           |\n",
    "| 🧩 Plug into tools    | Tie prompts to structured input/output schemas |\n",
    "| 📜 Instruction tuning | Teach models tone, persona, or behavior        |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Example: Few-Shot Prompt Template\n",
    "\n",
    "```python\n",
    "from mcp.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_examples(\n",
    "    input_variables=[\"food\"],\n",
    "    examples=[\n",
    "        {\"input\": \"apple\", \"output\": \"fruit\"},\n",
    "        {\"input\": \"carrot\", \"output\": \"vegetable\"}\n",
    "    ],\n",
    "    suffix=\"What category is {food}?\",\n",
    "    input_formatter=lambda vars: {\"food\": vars[\"food\"]}\n",
    ")\n",
    "```\n",
    "\n",
    "Then use this in your LLM call, and it will generate smart completions using the examples!\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ Prompt Types in MCP\n",
    "\n",
    "| Prompt Type      | Description                                           |\n",
    "| ---------------- | ----------------------------------------------------- |\n",
    "| `PromptTemplate` | Text templates + input vars + examples                |\n",
    "| `FewShotPrompt`  | Multiple structured examples before the actual prompt |\n",
    "| `MultiPrompt`    | Dynamic prompt switcher based on input or context     |\n",
    "| `EmbeddedPrompt` | Prompts tied to structured tool behavior              |\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ Real-Time Prompt Tricks\n",
    "\n",
    "| Tip                     | How It Helps                            |\n",
    "| ----------------------- | --------------------------------------- |\n",
    "| Use 🔁 suffixes         | Makes prompts more composable           |\n",
    "| Add ✍️ input variables  | Dynamically fill fields in templates    |\n",
    "| Include 🔍 examples     | LLMs learn better with few-shot samples |\n",
    "| Combine with 🎯 context | Refer to previously structured outputs  |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧱 Prompt + Tool Integration Example\n",
    "\n",
    "```python\n",
    "from mcp import tool, PromptTemplate\n",
    "\n",
    "@tool(prompt=\"Translate the following sentence to French: {text}\")\n",
    "def translate_to_french(text: str) -> str:\n",
    "    ...\n",
    "```\n",
    "\n",
    "🎯 You can also reuse structured prompts:\n",
    "\n",
    "```python\n",
    "from mcp.prompt import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_examples(\n",
    "    input_variables=[\"sentence\"],\n",
    "    examples=[\n",
    "        {\"input\": \"Hello\", \"output\": \"Bonjour\"},\n",
    "        {\"input\": \"Goodbye\", \"output\": \"Au revoir\"}\n",
    "    ],\n",
    "    suffix=\"Translate: {sentence}\"\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary\n",
    "\n",
    "| Feature            | Description                                       |\n",
    "| ------------------ | ------------------------------------------------- |\n",
    "| Few-shot Learning  | Feed examples directly to the LLM                 |\n",
    "| Structured Prompts | Templates with variables, suffixes, or examples   |\n",
    "| Tool Integration   | Attach prompts directly to your `@tool` decorator |\n",
    "| Reuse              | Modular, consistent, and testable LLM behaviors   |\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
